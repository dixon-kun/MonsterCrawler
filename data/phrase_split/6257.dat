company description
halo group is a premier provider of it
talent
we
place
technology
expert
within
the team of the world
leading
company
to help them
build
innovative
business
that
keep
them
one
step closer to
their
customer and one
step
ahead of the competition
we offer a meaningful work environment
for
employee
attractive
and interesting
engagement
for
consultant and cutting-edge
digital
innovation
for our customer
we
delight
in helping our customer
execute
their
digital
vision
big
project
or
small halo group
know that
by combining
the highest quality
talent
with
our
unwavering support
we
will become an invaluable extension of the team halo
group's experienced
consultant in detroit atlanta
and dallas
specialize in all
area of
product
project
governance
ux ui multi-platform application
quality
assurance
testing
cloud computing and data analytics
since it inception halo group
ha been recognized for
numerous
award
including
-
inc 5000
-
future
50
- 101 best
and brightest
- michigan 50 companies
to
watch
- goldline research
-
most dependable companies
- ernst young
-
entrepreneur
of the
year finalist
job description
preferred
selecting and integrating
big data
tool and framework
required to provide
requested
capability
implementing
data ingestion and etl process
on
hadoop
monitoring
performance and advising any
necessary
infrastructure
change
defining data retention
policy
design and build
data processing pipeline for
structured and unstructured data using
tool and framework
in the hadoop ecosystem
develop
application
that are
scalable
to handle
million of event
record
design and launch
scalable
reliable and efficient
process to move
transform and report
on
large amount of data
participate in meeting with
business
account
product management
data scientist to obtain
new
requirement
follow
our
agile software development
process
with
daily
scrum and monthly sprints
ability to work collaboratively
on a cross-functional team
with a wide range of experience
level
qualifications
bachelor's degree and8 year relevant experience
or masters degree
and
6 year of relevant experience
4 year
in
industry
implementing
big data
solution
on
hadoop
proficient
understanding of distributed computing
principle
proficiency with hadoop v2 mapreduce
hdfs
experience with
building stream-processing system
using
solution
such a
storm
or
kafka and spark-streaming
good knowledge of
big data querying tool such a
pig hive
phoenix
experience with
spark
experience with
integration of data from multiple data source
experience with
1 or
2
nosql
graph database
such a
hbase cassandra mongodb neo4j
proficiency in a
programming language like
scala java python
experience with linux os
shell scripting
experience with relational database
sql
experience in
working with
real-time data feed
experience in
working with
unstructured data
experience in implementing scoop jobs
to import export
data from
hadoop
knowledge of various
etl
technique and framework such a
pig hive or flume
experience with various
messaging system
such a kafka
or rabbitmq
experience with big data
ml toolkits such a
mahout sparkml or h2o
good understanding of lambda architecture
along with
it
advantage and drawback
experience with hortonworks hadoop
data platform
hdp
experience with
all
or
some of the following
supporting
hadoop
administration and security
framework hcatalog drill nifi
oozie falcon ranger ambari zeplin
qualifications
bachelor's degree or foreign equivalent
required
from
an accredited institution will also consider three year of progressive experience in the specialty in lieu of every
year of education
at least 2 year of experience with
information technology
additional information
us citizens and
those who are authorized to work independently
in the united states
are encouraged to apply
we are unable to sponsor at
this
time
this is a full-time permanent job
opportunity
only
for
us citizen and green card holder
all
your
information
will be kept confidential according to eeo guideline