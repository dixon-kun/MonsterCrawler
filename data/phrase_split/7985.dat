description
the role requires
working closely with
data science team
frequently in a matrixed environment
a part of
a broader
project
team
as a senior-level
position
the role requires
self-starter who are
proficient in
problem solving and capable of bringing
clarity to
complex situation
the
culture of the organization
place
an emphasis on
teamwork
so
social and interpersonal skill
are equally important
a technical
capability
due to
the
emerging and fast-evolving nature of
big data technology and practice
the position requires
that
one
stay well-informed of technological
advancement and
be proficient at putting new
innovation
into
effective
practice
responsibilities
this role will provide
application development
for
specific business
environment
focus on
setting
technical
direction
on
group of
application and
similar
technology
a well a
taking responsibility for
technically
robust
solution encompassing all
business
architecture and technology constraint
responsible for building and supporting
a hadoop-based ecosystem
designed for enterprise-wide
analysis of structured semi-structured and unstructured data
manage and optimize
hadoop spark
cluster
which
may include
many
large
hbase instance
support
regular
request to move data from
one
cluster
to
another
manage
production
support
team to make sure
service
level
are maintained and any interruption is resolved in a timely fashion
bring
new data source
into
hdfs
transform and load
to
database
work collaboratively with
data scientists and business and it
leader
throughout the company
to understand
big data
need and use case
qualifications
a successful candidate will have the following
bachelors degree in computer science or related discipline
with
at least 5 year of
equivalent work experience
strong understanding of
best practice and standard for
hadoop
application
design and implementation
hands-on experience with cloudera
distributed
hadoop cdh and
experience with many of the following
component
hadoop mapreduce spark impala hive
solr yarn
java python or scala
sql
json xml
regex
sqoop
experience in developing
mapreduce
program
using apache hadoop
for
working with big data
experience
having
deployed
big data technologies
to production
understanding of lambda design architectures and real-time streaming
ability to multitask and
to balance competing priority
requires
strong
practical experience in agile
application development
file system
management and devops
discipline and practice
using short-cycle iteration to deliver
continuous
business value
ability to define and utilize
best practice
technique and
to impose order
in a fast-changing environment
must have
strong problem-solving skill
strong verbal written and interpersonal skill
including
a desire to work
within a highly-matrixed team-oriented environment
preferred
a successful candidate
may
have
experience in healthcare
domain
experience in patient
data
hardware
operating
systems
linux
unix
distributed highly-scalable processing
environment
networking
-
basic understanding of networking
with respect to
distributed
server and file system connectivity and troubleshooting of connectivity error
databases

rdbms
teradata
other languages java python scala
r
build
systems
maven ant
source
control
systems
git mercurial
continuous integration
systems
jenkins or bamboo
config orchestration zookeeper puppet salt ansible chef
oozie
pig
certifications
a plus
but not required
ccdh cloudera
certified developer
for
apache hadoop