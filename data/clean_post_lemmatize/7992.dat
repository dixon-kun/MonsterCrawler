description
why hca
at it founding in 1968 nashville-based hca wa one of the nation's first hospital company today one of the nation's leading provider of healthcare service hca is comprised of locally-managed facility that include more than 250 hospital and freestanding surgery center in 20 state and the united kingdom employing approximately 230 000 people approximately four to five percent of all inpatient care delivered in the country today is provided by hca facility resulting in more than 26m patient encounter each year hca is committed to the care and improvement of human life and strives to deliver high quality cost effective healthcare in the community we serve building on the foundation provided by our mission values hca put patient first and work to constantly improve the care we provide by implementing measure that support our caregiver help ensure patient safety and provide the highest possible quality
additional facts
ranked 63 in fortune 500
competitive fortune 100 industry matched salary and yearly merit increase
computerworld top 50 best places to work in it since 2009
named one of the worlds most ethical companies since 2010
106 hca hospital are on the joint commissions list of top performer on key quality measure
job summary
this role will provide application development for specific business environment focus on setting technical direction on group of application and similar technology a well a taking responsibility for technically robust solution encompassing all business architecture and technology constraint
responsible for building and supporting a hadoop-based ecosystem designed for enterprise-wide analysis of structured semi-structured and unstructured data
manage and optimize hadoop spark cluster which may include many large hbase instance
support regular request to move data from one cluster to another
manage production support team to make sure service level are maintained and any interruption is resolved in a timely fashion
bring new data source into hdfs transform and load to database
work collaboratively with data scientists and business and it leader throughout the company to understand big data need and use case
qualifications
qualifications
strong understanding of best practice and standard for hadoop application design and implementation
hands-on experience with cloudera distributed hadoop cdh and experience with many of the following component
hadoop mapreduce spark streaming impala hive solr yarn
java python or scala
sql json xml
regex
sqoop
avro parquet
flume kafka
experience in developing mapreduce program using apache hadoop for working with big data
experience having deployed big data technologies to production
understanding of lambda design architectures and real-time streaming
ability to multitask and to balance competing priority
requires strong practical experience in agile application development file system management and devops discipline and practice using short-cycle iteration to deliver continuous business value
ability to define and utilize best practice technique and to impose order in a fast-changing environment must have strong problem-solving skill
strong verbal written and interpersonal skill including a desire to work within a highly-matrixed team-oriented environment
preferred
a successful candidate may have
experience in healthcare domain
experience in patient data
hardware operating systems
linux
unix
distributed highly-scalable processing environment
networking - basic understanding of networking with respect to distributed server and file system connectivity and troubleshooting of connectivity error
databases

rdbms teradata
other languages java python scala r
build systems maven ant
source control systems git mercurial
continuous integration systems jenkins or bamboo
config orchestration zookeeper puppet salt ansible chef oozie pig
certifications a plus but not required
ccdh cloudera certified developer for apache hadoop