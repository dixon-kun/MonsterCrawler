(dp1
S'concept'
p2
F0.011958
sS'experience working'
p3
F0.011453
sS'probability statistics'
p4
F0.033769
sS'code'
p5
F0.012507000000000001
sS'identify'
p6
F0.0084510000000000002
sS'statistical'
p7
F0.0093779999999999992
sS'easy access'
p8
F0.036902999999999998
sS'messy'
p9
F0.036902999999999998
sS'speed'
p10
F0.021964000000000001
sS'write'
p11
F0.017534999999999999
sS'personal'
p12
F0.016855999999999999
sS'casualty insurance'
p13
F0.045407999999999997
sS'extensive'
p14
F0.020055
sS'optimization techniques'
p15
F0.047895
sS'strength andlocal operation'
p16
F0.052148
sS'exceptional'
p17
F0.016192000000000002
sS'expectation'
p18
F0.022192
sS'preferred'
p19
F0.017645000000000001
sS'unstructured'
p20
F0.019581999999999999
sS'test'
p21
F0.011939999999999999
sS'report'
p22
F0.0085450000000000005
sS'using'
p23
F0.0068110000000000002
sS'like'
p24
F0.013207
sS'54 country chubb providescommercial'
p25
F0.052148
sS'follows'
p26
F0.03108
sS'qualitative'
p27
F0.024407000000000002
sS'solution'
p28
F0.0043620000000000004
sS'capability'
p29
F0.010681
sS'linear algebra'
p30
F0.032399999999999998
sS'mathematical'
p31
F0.016192000000000002
sS'predictive'
p32
F0.014285000000000001
sS'financial'
p33
F0.011802
sS'java python'
p34
F0.026928000000000001
sS'foundation'
p35
F0.019990000000000001
sS'frame'
p36
F0.030884999999999999
sS'good understanding'
p37
F0.023366000000000001
sS'library'
p38
F0.040924000000000002
sS'information retrieval'
p39
F0.023037999999999999
sS'database querying'
p40
F0.038668000000000001
sS'statistic'
p41
F0.011231
sS'operation'
p42
F0.011310000000000001
sS'multiple source'
p43
F0.023199999999999998
sS'science ofderiving insight'
p44
F0.052148
sS'scale'
p45
F0.013805
sS'deep understanding'
p46
F0.018974999999999999
sS'personal accident andsupplemental health insurance reinsurance'
p47
F0.052148
sS'strongbackground'
p48
F0.047895
sS'current'
p49
F0.012975
sS'behind'
p50
F0.025579000000000001
sS'interpret data'
p51
F0.031927999999999998
sS'business partner'
p52
F0.017135000000000001
sS'insurance industry experience'
p53
F0.047895
sS'1 year'
p54
F0.019893000000000001
sS'basic qualifications'
p55
F0.013852
sS'core'
p56
F0.012772
sS'ability'
p57
F0.0034840000000000001
sS'business'
p58
F0.0042139999999999999
sS'data scientist'
p59
F0.0040530000000000002
sS'job'
p60
F0.0073029999999999996
sS'hypothesis'
p61
F0.024081999999999999
sS'bs'
p62
F0.018550000000000001
sS'spark'
p63
F0.015004
sS'strong'
p64
F0.012446
sS'distribution'
p65
F0.021531999999999999
sS'modelling technique'
p66
F0.042273999999999999
sS'advance'
p67
F0.017779
sS'data visualization'
p68
F0.014336
sS'technical'
p69
F0.0058329999999999996
sS'specificresponsibilities'
p70
F0.052148
sS'experience'
p71
F0.0034380000000000001
sS'supervised'
p72
F0.025340999999999999
sS'serviceofferings broad'
p73
F0.052148
sS'organize'
p74
F0.022675000000000001
sS'computer science math statistics'
p75
F0.038020999999999999
sS'scikit-learn xgboost nltk panda matplotlib'
p76
F0.047895
sS'industry experience'
p77
F0.020055
sS'apply'
p78
F0.017232000000000001
sS'quality'
p79
F0.010260999999999999
sS'ideal candidate'
p80
F0.015106
sS'art'
p81
F0.024473999999999999
sS'working'
p82
F0.0066540000000000002
sS'deep learning'
p83
F0.037839999999999999
sS'create'
p84
F0.0082410000000000001
sS'structured'
p85
F0.014749999999999999
sS'quantitative'
p86
F0.011389
sS'complex data set'
p87
F0.027907000000000001
sS'high performance'
p88
F0.022932000000000001
sS'examine predictor'
p89
F0.047895
sS'analyze'
p90
F0.010869
sS'machine learning algorithm'
p91
F0.016993999999999999
sS'diversegroup'
p92
F0.052148
sS'acquire'
p93
F0.027029000000000001
sS'disparate data source predictivemodelling'
p94
F0.052148
sS'job description'
p95
F0.012411999999999999
sS'understand'
p96
F0.0087390000000000002
sS'related'
p97
F0.0085299999999999994
sS'non-technical audience'
p98
F0.020289000000000001
sS'clean unify'
p99
F0.047895
sS'unsupervised learning neural networks ensembling understanding'
p100
F0.047895
sS'apis scraping'
p101
F0.047895
sS"world's largest publicly tradedproperty"
p102
F0.052148
sS'must'
p103
F0.0085599999999999999
sS'preffered'
p104
F0.09579
sS'datasets'
p105
F0.018422999999999998
sS'ml'
p106
F0.025113
sS'work'
p107
F0.002137
sS'probabilistic'
p108
F0.032911000000000003
sS'r'
F0.0092189999999999998
sS'ms'
p109
F0.014158
sS'least 1 year'
p110
F0.029516000000000001
sS'investigating'
p111
F0.028398
sS'problem'
p112
F0.0084899999999999993
sS'property'
p113
F0.027029000000000001
sS'similar'
p114
F0.013899999999999999
sS'gathering'
p115
F0.026633
sS'exposure'
p116
F0.037359000000000003
sS'defined'
p117
F0.023654000000000001
sS'describe'
p118
F0.029073000000000002
sS'visual aid'
p119
F0.043643000000000001
sS'client chubb'
p120
F0.047895
sS'globally'
p121
F0.023713999999999999
sS'raw'
p122
F0.035138000000000003
sS'large data set'
p123
F0.015786000000000001
sS'chubb'
p124
F0.047895
sS'hadoop'
p125
F0.011897
sS'data scientistis'
p126
F0.052148
sS'cleansing'
p127
F0.031489000000000003
sS'communicate result'
p128
F0.023538
sS'also'
p129
F0.010163
sS'role'
p130
F0.0063800000000000003
sS'build'
p131
F0.0059839999999999997
sS'extensive knowledge'
p132
F0.025499000000000001
sS'unstructured data'
p133
F0.016914999999999999
sS'accuracy'
p134
F0.020289000000000001
sS'product'
p135
F0.0046319999999999998
sS'casualty insurer'
p136
F0.043643000000000001
sS'models'
p137
F0.029995000000000001
sS'proficiency'
p138
F0.011861999999999999
sS'sql'
p139
F0.0068219999999999999
sS'variable'
p140
F0.027675000000000002
sS'data'
p141
F0.0059870000000000001
sS'skillsrequired'
p142
F0.052148
sS'relationship calculate basic'
p143
F0.047895
sS'algorithm'
p144
F0.0076229999999999996
sS'theano tensorflow kera torch etc'
p145
F0.047895
sS'required'
p146
F0.0059439999999999996
sS'big data technology'
p147
F0.017195999999999999
sS'analysis'
p148
F0.0050270000000000002
sS'consistency'
p149
F0.030512999999999998
sS'life insurance'
p150
F0.024146000000000001
sS'professional'
p151
F0.010803
sS'model'
p152
F0.0061110000000000001
sS'requires'
p153
F0.019057999999999999
s.