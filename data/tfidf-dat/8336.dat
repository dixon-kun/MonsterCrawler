(dp1
S'via'
p2
F0.077890000000000001
sS'mandatory'
p3
F0.14318700000000001
sS'hadoop'
p4
F0.048479000000000001
sS'report'
p5
F0.034821999999999999
sS'code'
p6
F0.050967999999999999
sS'need'
p7
F0.026891000000000002
sS'tools'
p8
F0.11099000000000001
sS'information'
p9
F0.028875000000000001
sS'different'
p10
F0.061142000000000002
sS'develop'
p11
F0.019501000000000001
sS'working'
p12
F0.027115
sS'representing'
p13
F0.13411400000000001
sS'storage'
p14
F0.096153000000000002
sS'feature'
p15
F0.064531000000000005
sS'various'
p16
F0.043207000000000002
sS'take'
p17
F0.051561000000000003
sS'data scientists'
p18
F0.065559999999999993
sS'type'
p19
F0.066559999999999994
sS'duties'
p20
F0.079920000000000005
sS'nice'
p21
F0.093878000000000003
sS'sort'
p22
F0.13202900000000001
sS'visualizing data'
p23
F0.14652499999999999
sS'data scientist'
p24
F0.033031999999999999
sS'understanding'
p25
F0.032127000000000003
sS'datasets'
p26
F0.075073000000000001
sS'represented'
p27
F0.172265
sS'acquiring'
p28
F0.13202900000000001
sS'spark'
p29
F0.061142000000000002
sS'data'
p30
F0.060997999999999997
sS'sorting'
p31
F0.172265
sS'dispatch work'
p32
F0.212501
sS'java'
p33
F0.056693
sS'work'
p34
F0.0087069999999999995
sS"data lake 'prepping'"
p35
F0.212501
sS'joining'
p36
F0.085936999999999999
s.