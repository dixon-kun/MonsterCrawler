Job
Description
The
Biomedical
Informatics
Department
at
Emory
University
is
looking
for
a
Research
Scientist
in
Big
Data
Management
and
Integration
You
will
be
responsible
for
researching
and
developing
data
engineering
solutions
to
integrate
and
federate
data
from
various_sources
of
cancer_research
in
the
Internet
scale
As
a
member
of
our
research
group
you
will
be
expected
to
design_implement
and
deploy
distributed_systems
to
manage
data
of
heterogeneous
nature
storage
and
communication
We
are
looking
for
someone
with
a
solid_understanding
and
experience
on
distributed_systems
and
cloud_computing
and
is
interested
in
learning
and
applying
cutting_edge
technologies
for
the
challenges
of
performance
and
scale
The
ideal_candidate
would
be
an
independent
yet
a
team_player
with
keen_interest
to
collaborating
and
coordinating
with
the
team
working
on
the
data
sciences
research
This
work
is
part
of
a
large
NIH-funded
project
What
this
means
is
that
you
will
help
develop
an
exciting
piece
of
technology
that
will
be
part
of
a
national
infrastructure
supporting
cancer_research
one
that
brings_together
disparate
cancer
datasets
and
gives
the
research
community
the
ability
to
examine_data
like_never
before
Your
work
will
have
direct_impact
on
cancer_research
and
will
become
widely
known
through
national
and
international
adoption
collaborative
participation
in
large-scale
projects
and
open_source
software
efforts
and
most
importantly
in
advancing
healthcare
The
ideal_candidate
is
one
who
is
motivated
by
challenging
applications
and
is
interested
in
exploring
how
advances
in
distributed_computing
and
cloud_computing
can
benefit
healthcare
We
collaborate_extensively
with
well-known
research
groups
from
prominent
institutions
and
draw
upon
the
first
rate
technical
and
scientific
resources_available
at
Emory
and
Georgia
Tech
Qualifications
You
will
be
primarily
developing
server_side
applications
using
Java
and
a
variety
of
open-source_big
data
frameworks
such
as
Apache
Drill
and
Hadoop
You
will
build_upon
a
suite
of
existing_systems
that
have
been
built
in
our
lab
and
help
add
new_functionality
and
increase
the
scale
of
storage
complexity
of
data
and
the
variety
of
data
types
Required
PhD
in
Computer
Science
or
Computer
Engineering
with
an
emphasis
on
Distributed
Computing
Cloud
Computing
HPC
Expert
in
developing
enterprise
applications
with
Java
with
experience
in
concurrent
computing
and
streams
Experienced
in
distributed_systems
principles
execution
frameworks
such
as
Hazelcast
and
Infinispan
and
distributed_storage
and
processing
frameworks
such
as
Apache
Hadoop
Working
knowledge
of
SQL
and
NoSQL
databases
Comfortable
with
public
and
private
cloud_deployments
including
the
Amazon
web_services
AWS
Experienced
in
web_services
engines
and
development
of
RESTful
APIs
and
web_services
Experienced
in
various
architectures
and
paradigms
such
as
SOA
and
OSGi
Unit
and
integration_testing
version_control
Git
and
project_management
tools_like
Maven
Track
record
of
presenting
at
premier
conferences
and
publishing
in
relevant
journals