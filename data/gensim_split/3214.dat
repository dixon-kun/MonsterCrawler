Req
ID
40340BR
POSITION
SUMMARY
Data
Platform
Engineering's
mission
is
to
provide
core
development
and
support
functions
for
our
in-house
Enterprise
Ingestion
Framework
and
peripheral_products
used
to
move
and
transform
data
in
the
Hadoop
enterprise
environment
Our
team
is
seeking
a
data
platform
engineer
to
support
our
growing
Big
Data
ecosystem_built
on
Hadoop
In
this
role
you
will
collaborate
with
our
Infrastructure
and
Data
Science
communities
to
develop
and
maintain
data_ingestion
utilities
and
support
Linux-based
software
products
that
our
business
customers
use
to
derive_value
from
data
The
ideal_candidate
has
a
passion
for
big_data
technology
and
is
excited
to
join_us
in
delivering
best-in-class
ingestion
protection
and
presentation
capabilities
FUNDAMENTAL
COMPONENTS
-
Engineer
and
Administer
big_data
infrastructure
platform
primarily_based
on
Hadoop
based
technologies
ensuring
that
the
infrastructure
is
highly-available
and
secure
-
Manage
security_compliant
user
management
framework
for
multi-tenant_big
data
platform
-
Work
closely
with
Management
and
Data
Scientist
teams
to
refine
the
big_data
platform
to
achieve
company
product
and
business_objectives
-
Collaborate
with
other
technology
teams
and
architects
to
define
and
develop_cross-function
technology_stack
interactions
-
Research
and
experiment
with
emerging_technologies
and
tools
related
to
big_data
-
Work
with
the
Engineering
management
team
to
establish
and
reinforce_disciplined
software_development
processes
and
best-practices
-
Maintain
and
support
the
platform
on
a
day-to-day_basis
BACKGROUND
EXPERIENCE
DESIRED
-
Bachelor's
degree
in
Computer
Science
or
equivalent
experience
-
At
least_2
years
of
experience
building
and
managing_complex
products
solutions
-
Understanding
of
Big
Data
concepts
and
common_components
including
YARN
Queues
Hive
Beeline
AtScale
Datameer
Kafka
and
HDF
-
Familiarity
with
and
use
of
encryption
and
masking_technologies
relative
to
data
storage
and
network
communications
-
Demonstrates
Awareness
of
multiple
infrastructure
disciplines
-
2_+
years
of
experience
with
distributed
highly-scalable
multi-node
environments
-
Understands
the
concepts
and
technology_ecosystem
around
both
real-time
and
batch_processing
in
Hadoop
-
Familiarity
in
Dev
Ops
Puppet
Chef
Python
-
Awareness
of
web_technologies
and
protocols
JAVA
NoSQL
JSON
REST
JMS
EDUCATION
The
minimum
level
of
education_desired
for
candidates
in
this
position
is
a
Bachelor's
degree
or
equivalent
experience
ADDITIONAL
JOB
INFORMATION
Aetna
is
about
more
than
just
doing
a
job
This
is
our
opportunity
to
re-shape_healthcare
for
America
and
across
the
globe
We
are
developing_solutions
to
improve
the
quality
and
affordability
of
healthcare
What
we
do
will
benefit_generations
to
come
We
care
about
each
other
our
customers
and
our
communities
We
are
inspired
to
make
a
difference
and
we
are
committed
to
integrity
and
excellence
Together
we
will
empower_people
to
live_healthier
lives
Aetna
is
an
equal_opportunity
affirmative_action
employer
All
qualified_applicants
will
receive_consideration
for
employment_regardless
of
personal_characteristics
or
status
We
take_affirmative
action
to
recruit
select
and
develop
women
people
of
color
veterans
and
individuals
with
disabilities
We
are
a
company_built
on
excellence
We
have
a
culture
that
values
growth
achievement
and
diversity
and
a
workplace
where
your
voice
can
be
heard
Benefit
eligibility_may
vary
by
position
Click
here
to
review
the
benefits_associated
with
this
position
Aetna
takes
our
candidate's_data
privacy
seriously
At
no
time
will
any
Aetna
recruiter
or
employee_request
any
financial
or
personal_information
Social
Security
Number
Credit
card_information
for
direct
deposit
etc
from
you
via
e-mail
Any
requests
for
information
will
be
discussed_prior
and
will
be
conducted
through
a
secure_website
provided
by
the
recruiter
Should
you
be
asked
for
such
information
please_notify
us
immediately
Job
Function
Information
Technology