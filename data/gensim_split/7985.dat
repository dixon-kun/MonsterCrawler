Description
The
role_requires
working_closely
with
data_science
teams
frequently
in
a
matrixed_environment
as
part
of
a
broader
project
team
As
a
senior-level
position
the
role_requires
self-starters
who
are
proficient
in
problem_solving
and
capable
of
bringing
clarity
to
complex
situations
The
culture
of
the
organization
places
an
emphasis
on
teamwork
so
social
and
interpersonal_skills
are
equally_important
as
technical
capability
Due
to
the
emerging
and
fast-evolving
nature
of
Big
Data
technology
and
practice
the
position_requires
that
one
stay
well-informed
of
technological
advancements
and
be
proficient
at
putting
new
innovations
into
effective
practice
Responsibilities
This
role
will
provide
application_development
for
specific
business
environments
Focus
on
setting
technical_direction
on
groups
of
applications
and
similar
technologies
as
well
as
taking_responsibility
for
technically_robust
solutions
encompassing
all
business
architecture
and
technology
constraints
Responsible
for
building
and
supporting
a
Hadoop-based
ecosystem_designed
for
enterprise-wide
analysis
of
structured
semi-structured
and
unstructured_data
Manage
and
optimize
Hadoop
Spark
clusters
which
may_include
many
large
HBase
instances
Support
regular
requests
to
move
data
from
one
cluster
to
another
Manage
production
support
teams
to
make_sure
service
levels
are
maintained
and
any
interruption
is
resolved
in
a
timely_fashion
Bring
new
data_sources
into
HDFS
transform
and
load
to
databases
Work
collaboratively
with
Data
Scientists
and
business
and
IT
leaders
throughout
the
company
to
understand
Big
Data
needs
and
use_cases
Qualifications
A
successful_candidate
will
have
the
following
Bachelors
degree
in
Computer
Science
or
related_discipline
with
at
least_5
years
of
equivalent_work
experience
Strong
understanding
of
best_practices
and
standards
for
Hadoop
application
design
and
implementation
Hands-on
experience
with
Cloudera
Distributed
Hadoop
CDH
and
experience
with
many
of
the
following
components
Hadoop
MapReduce
Spark
Impala
Hive
Solr
YARN
Java
Python
or
Scala
SQL
JSON
XML
RegEx
Sqoop
Experience
in
developing
MapReduce
programs
using
Apache
Hadoop
for
working
with
Big
Data
Experience
having
deployed
Big
Data
Technologies
to
Production
Understanding
of
Lambda
Design
Architectures
and
Real-Time
Streaming
Ability
to
multitask
and
to
balance_competing
priorities
Requires
strong
practical
experience
in
agile
application_development
file_systems
management
and
DevOps
discipline
and
practice
using_short-cycle
iterations
to
deliver
continuous
business
value
Ability
to
define
and
utilize
best_practice
techniques
and
to
impose_order
in
a
fast-changing
environment
Must
have
strong_problem-solving
skills
Strong
verbal_written
and
interpersonal_skills
including
a
desire
to
work
within
a
highly-matrixed
team-oriented_environment
Preferred
A
successful_candidate
may
have
Experience
in
Healthcare
Domain
Experience
in
Patient
Data
Hardware
Operating
Systems
Linux
UNIX
Distributed
highly-scalable_processing
environments
Networking
-
basic_understanding
of
networking
with
respect
to
distributed
server
and
file_systems
connectivity
and
troubleshooting
of
connectivity_errors
Databases
RDBMS
Teradata
Other
Languages
Java
Python
Scala
R
Build
Systems
Maven
Ant
Source
Control
Systems
Git
Mercurial
Continuous
Integration
Systems
Jenkins
or
Bamboo
Config
Orchestration
Zookeeper
Puppet
Salt
Ansible
Chef
Oozie
Pig
Certifications
a
plus
but
not
required
CCDH
Cloudera
Certified
Developer
for
Apache
Hadoop