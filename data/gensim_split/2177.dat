As
a
Senior
Data
Engineer
in
the
Aero
Services
organization
you
will
be
responsible
for
designing_building
and
maintaining
our
Big
Data
platform
and
massive
data_stores
on
which
our
data
analytics
applications
and
tools
run
on
Key
to
the
growth
of
the
Aero
Services
Org
will
be
our
ability
to
monetize_critical
data
that
is
produced
by
our
suite
of
Aerospace
products
Main
Responsibilities
Design
develop
and
maintain
the
Big
Data
platform
that
is
fault-tolerant
and
scalable
Design
develop
and
maintain
cross-platform
ETL
processes
and
maintain
dimensions
and
reference
lookup
dictionaries
Develop
guidelines_standards
and
processes
to
ensure
the
highest
data
quality
and
integrity
in
the
data_stores
residing
on
the
Big
Data
platform
Participate
in
setting_strategy
and
standards
through
data
architecture
and
implementation
leveraging
big_data
and
analytics
tools
and
technologies
Work
closely
with
data_scientists
and
product_managers
to
understand
their
data
requirements
for
existing
and
future
projects
on
data
analytics
applications
Work
with
IT
and
data
owners
to
understand
the
types
of
data_collected
in
various
databases
and
data_warehouses
and
define
the
migration
strategy
to
move
existing
data
into
the
Big
Data
platform
Additional
Attributes
Keen
business_acumen
to
recognize
and
recommend_cost-effective
and
scalable
platform
solutions
that
best_meet
our
business_needs
Ability
to
execute_projects
using
an
agile
approach
in
a
multi-disciplinary
matrixed_environment
Comfortable
working
in
a
dynamic
research
and
development
environment
with
several_ongoing
concurrent_projects
Enjoys
exploring
and
learning
new_technologies
You
Must
Have
Bachelor
degree
in
computer_science
IT
engineering
or
other
relevant_field
with
a
minimum
of
5_years
of
data
management
experience
Minimum
of
3_years
of
experience
in
designing_deploying
and
supporting
Big
Data
systems
and
solutions
Minimum
of
3_years
of
experience
in
migrating
data
from
data_sources
MS
SQL
Oracle
MySQL
etc
into
Hadoop
platform
using
Hadoop
frameworks
Spark
Hive
Pig
Sqoop
Flume
etc
Must
be
a
US
person
US
citizen
US
permanent_resident
or
individual
with
protected_status
ie
asylum
refugee
due
to
US
export_control
laws
and
regulations
We
Value
Minimum
of
2_years
of
experience
in
scripting_languages
Perl
Python
Java
etc
Minimum
of
2_years
of
experience
in
NoSQL
solutions
Hbase
Cassandra
MongoDB
CouchDB
etc
and
managing
unstructured_data
Masters
or
PhD
degrees
in
computer_science
IT
engineering
or
relevant_fields
Certification
in
Hadoop
and
other
big_data
tools
and
technologies
Experience
with
open_source
data
processing
frameworks
Experience
with
data
management
on
public_cloud
hosting_services
Experience
with
predictive_analytics
Experience
with
web
analytics
and
managing
social_media
data_streams
Experience
with
Agile
software_development
methodology
Ability
to
work
in
a
fast-paced
and
ambiguous_environment