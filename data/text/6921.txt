('&#', 30)('8226', 25)('data', 21)('and', 19)('a', 18)('of', 15)('Data', 14)('-', 13)('to', 11)('the', 11)('with', 11)('on', 9)('NJ', 7)('must.', 6)('analytics', 6)('for', 6)('Hadoop', 5)('160', 5)('is', 5)('in', 5)('etc.', 5)('experience', 4)('plus.', 4)('programming', 4)('engineer', 4)('complex', 4)('using', 4)('be', 4)('business', 4)('Transformation', 3)('&amp', 3)('Integration', 3)('Digital', 3)('Complex', 3)('Work', 3)('Parsing', 3)('The', 3)('solutions', 3)('should', 3)('solutions.', 3)('Engineer', 3)('able', 3)('big', 3)('Chubb', 3)('or', 3)('Knowledge', 3)('Experience', 3)('as', 3)('HBase', 2)('(NLP)', 2)('skills', 2)('large', 2)('design', 2)('relational', 2)('Mahout', 2)('tools', 2)('this', 2)('science', 2)('Whitehouse', 2)('information', 2)('Spark', 2)('A', 2)('Hive', 2)('Brunswick', 2)('Parser)', 2)('Natural', 2)('Language', 2)('R', 2)('preparation', 2)('have', 2)('multiple', 2)('who', 2)('knowledge', 2)('computer', 2)('managing', 2)('3', 2)('discovery', 2)('Piscataway', 2)('Processing', 2)('will', 2)('Ideal', 2)('different', 2)('Python', 2)('sets', 2)('visualization', 2)('candidate', 2)('background', 2)('projects', 2)('like', 2)('Pig', 2)('New', 2)('software', 2)('into', 2)('within', 2)(':', 2)('technologies', 2)('problems', 2)('(Big', 2)('focus', 1)('Station', 1)('visualizing', 1)('cloud.', 1)('data-driven', 1)('activities', 1)('results', 1)('decide', 1)('HDFS', 1)('Global', 1)('prototypes', 1)('Transforms', 1)('team', 1)('Should', 1)('Real-Time', 1)('selected', 1)('above', 1)('tasks.', 1)('wrangling', 1)('commercial', 1)('languages.', 1)('strong', 1)('technical', 1)('analysts', 1)('Big', 1)('implement', 1)('Technology', 1)('highly', 1)('analyzing', 1)('from', 1)('working', 1)('0', 1)('Solr', 1)('Require', 1)('Required', 1)('Apache', 1)('American', 1)('insights', 1)('concepts', 1)('strategies', 1)('proof', 1)('(with', 1)('high', 1)('educational', 1)('requirements', 1)('cleansing', 1)('1', 1)('responsibilities', 1)('Significant', 1)('needs', 1)('Will', 1)('applications', 1)('effective', 1)('platforms.', 1)(')', 1)('algorithms', 1)('years', 1)('including', 1)('statistical', 1)('converting', 1)('solving', 1)('2017', 1)('someone', 1)('emailed', 1)('Cloudera', 1)('python', 1)('ingestion.', 1)('Bedminster', 1)('Diedre', 1)('Mill', 1)('|', 1)('loads.', 1)('related', 1)('self-starter', 1)('receiving', 1)('Spark.', 1)('Specific', 1)('training', 1)('certifications', 1)('turn', 1)('follows:', 1)('313326', 1)('one', 1)('another', 1)('management', 1)('MapR', 1)('needed', 1)('2', 1)('master', 1)('that', 1)('tool', 1)('to:', 1)('10', 1)('target', 1)('AT&amp', 1)('Cassandra', 1)('collecting', 1)('Information', 1)('Parsippany', 1)('substantial', 1)('any', 1)('depending', 1)('conforming', 1)('build', 1)('architects', 1)('Ingestion', 1)('especially', 1)('Avro', 1)('databases', 1)('High-Speed', 1)('ZooKeeper', 1)('partners', 1)('based', 1)('(', 1)('outside', 1)('08889', 1)('closely', 1)('she', 1)('formats.', 1)('PM', 1)('Chukwa', 1)('Leverage', 1)('Create', 1)("Hall's", 1)('are', 1)('Performance', 1)('needs.', 1)('techniques', 1)('08', 1)('various', 1)('profiling', 1)('jobs', 1)('premises', 1)('deliver', 1)('implementing', 1)('job', 1)('adept', 1)('according', 1)('Design', 1)('create', 1)('.', 1)('JSON', 1)('utilizing', 1)('XML', 1)('sufficient', 1)('BridgeView', 1)('understand', 1)('worked', 1)('those', 1)('developing', 1)('solid', 1)('engineering', 1)('use.', 1)('MapReduce', 1)('hardware', 1)('Moire', 1)('You', 1)('technology', 1)('develop', 1)('development', 1)('IT', 1)('{emailaddress}', 1)('levels', 1)('ownership', 1)('stack', 1)('tune', 1)('Limited', 1)('1600', 1)('well', 1)('model', 1)('latest', 1)('ecosystem.', 1)('being', 1)('sources', 1)('speed', 1)('eager', 1)('Hands', 1)('take', 1)('rules', 1)('aggregation', 1)('T', 1)('ecosystems', 1)('58', 1)('HortonWorks', 1)('Streaming', 1)('Linux)', 1)('works', 1)('Warren', 1)('Java', 1)('and/or', 1)('broad', 1)('LLC', 1)('He', 1)('communicate', 1)('Sourcing', 1)('leadership', 1)('by', 1)('range', 1)('plus', 1)('act', 1)('Cybersystems', 1)('repositories.', 1)('No', 1)('parsing', 1)('analysis.', 1)('Knowledgent', 1)('statistics', 1)('fields.', 1)('abstractions', 1)('Collection', 1)('custom', 1)('start', 1)('Excellent', 1)('perform', 1)('form', 1)('Itlize', 1)('decisions.', 1)('Interactive', 1)('datasets', 1)('high-quality', 1)('ecosystem', 1)('Tez', 1)('non-relational', 1)('distribution', 1)('sqoop', 1)('Utilize', 1)('diverse', 1)('expertise', 1)('at', 1)('Mar', 1)('variety', 1)('generally', 1)('other', 1)('role', 1)('Corp.', 1)('Case', 1)('Hadooop', 1)('"raw"', 1)('Skills', 1)('tackle', 1)('Implement', 1)('visual', 1)('Jobs.com', 1)('requires', 1)    Data Engineer, Digital Transformation &amp; Integration - Chubb Limited | Jobs.com
               Data Engineer, Digital Transformation &amp; Integration              (
               313326              )
               The data engineer is a technical job that requires substantial expertise in a broad range of software development and programming fields. The data engineer should especially have sufficient knowledge of big data solutions to be able to implement those on premises or in the cloud.
               A data engineer generally works on implementing complex big data projects with a focus on collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms. He or she should be able to decide on the needed hardware and software design needs and act according to the decisions. The big data engineer should be able to develop prototypes and proof of concepts for the selected solutions.
               Ideal candidate for this role is someone with a strong background in computer programming, statistics, and data science who is eager to tackle problems with large, complex datasets using the latest python, R, and/or Spark. &#160; Require a self-starter who will take ownership of projects and deliver high-quality data-driven analytics solutions. &#160;Ideal candidate is adept at solving diverse business problems by utilizing a variety of different tools, strategies, algorithms and programming languages.
               Specific responsibilities are as follows:
               &#8226; Utilize the data engineering skills within and outside of the developing Chubb information ecosystem for discovery, analytics and data management
               &#8226; Work with architects, business partners and business analysts to understand requirements, design and build effective solutions.
               &#8226; Will be using Data wrangling techniques converting one "raw" form into another including data visualization, data aggregation, training a statistical model etc.
               &#8226; Create different levels of abstractions of data depending on analytics needs.
               &#8226; Hands on data preparation activities using the Hadoop technology stack
               &#8226; Implement discovery solutions for high speed data ingestion.
               &#8226; Work closely with the Data leadership team to perform complex analytics and data preparation tasks.
               &#8226; Work with various relational and non-relational data sources with the target being Hadoop based repositories.
               &#8226; Sourcing data from multiple applications, profiling, cleansing and conforming to create master data sets for analytics use.
               &#8226; Experience with Complex Data Parsing (Big Data Parser) and Natural Language Processing (NLP) Transforms on Hadoop a plus.
               &#8226; Design solutions for managing highly complex business rules within the Hadoop ecosystem.
               &#8226; Performance tune data loads.
               &#8226; Leverage visual analytics tools to communicate results of data analysis.
               Skills Required
               &#8226; 1-3 years of solid experience in Big Data technologies a must.
               &#8226; Knowledge of Hadooop 2.0 ecosystems, HDFS, MapReduce, Hive, Pig, sqoop, Mahout, Spark etc. a must.
               &#8226; Experience with Avro, Cassandra, Chukwa, HBase, Hive, Mahout, Pig, Spark, Tez, ZooKeeper etc. a must.
               &#8226; Significant programming experience (with above technologies as well as Java, R and Python on Linux) a must.
               &#8226; Knowledge of any commercial distribution like HortonWorks, Cloudera, MapR etc. a must.
               &#8226; Excellent working knowledge of relational databases, HBase etc.
               &#8226; A computer science or related educational background
               &#8226; Data visualization tool experience a plus.
               &#8226; Hadoop certifications a plus.
               &#8226; Experience with Complex Data Parsing (Big Data Parser) a must. Should have worked on XML, JSON and other custom Complex Data Parsing formats.
               &#8226; Natural Language Processing (NLP) skills with experience in Apache Solr, Python a plus
               &#8226; Knowledge of High-Speed Data Ingestion, Real-Time Data Collection and Streaming is a plus.
                Chubb Whitehouse - Hall's Mill
                Whitehouse Station                &#160;                08889-1600
               Information Technology
               -              &#160;              No
               -              &#160;              Mar 10, 2017, 3:08:58 PM
             Case Interactive, Piscataway - NJ
             AT&amp;T, Bedminster - NJ
             BridgeView IT, Parsippany - NJ
             Diedre Moire Corp., New Brunswick - NJ
             American Cybersystems, New Brunswick - NJ
             Knowledgent, Warren - NJ
             Itlize Global LLC, Piscataway - NJ
          Data Engineer, Digital Transformation &amp; Integration
        You will start receiving jobs like this emailed to: {emailaddress}