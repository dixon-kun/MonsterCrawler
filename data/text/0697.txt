('and', 55)('&#', 53)('8226', 52)('the', 30)('of', 28)('to', 26)('in', 26)('with', 25)('experience', 17)('a', 17)('data', 14)('Data', 13)('years', 9)('Hadoop', 9)('for', 9)('as', 9)('tools', 8)('-', 8)('architecture', 7)('or', 7)('NY', 7)('Experience', 7)('environment', 6)('this', 6)('Familiarity', 6)('architectures', 6)('on', 6)('technologies', 6)('system', 5)('hands-on', 5)('solutions', 5)('York', 5)('is', 5)('New', 5)('business', 5)('Lead', 4)('team', 4)('Architect', 4)('The', 4)('enterprise', 4)('knowledge', 4)('Ability', 4)('ability', 4)('City', 4)('big', 4)('Management', 4)('platforms', 4)('skills', 3)('large', 3)('design', 3)('new', 3)('technical', 3)('Inc', 3)('working', 3)('information', 3)('applications', 3)('such', 3)('Minimum', 3)('Platform', 3)('Work', 3)('2', 3)('multiple', 3)('Big', 3)('guidance', 3)('reference', 3)('will', 3)('development', 3)('well', 3)('Hands', 3)('role', 3)('using', 3)('like', 3)('scale', 3)('integration', 3)('architectural', 3)('MPP', 3)('Teradata', 3)('delivery', 3)('other', 3)('and/or', 3)('lead', 3)('solution', 2)('work', 2)('access', 2)('This', 2)('designing', 2)('understanding', 2)('warehousing', 2)('implement', 2)('manage', 2)('cloud', 2)('&amp', 2)('8', 2)('clients', 2)('process', 2)('minimum', 2)('1', 2)('platform', 2)('domain', 2)('principles', 2)('year', 2)('Architecture', 2)('priorities', 2)('one', 2)('message', 2)('open', 2)('least', 2)('that', 2)('Emvia', 2)('solutions.', 2)('Hortonworks', 2)('have', 2)('need', 2)('architects', 2)('position', 2)('drive', 2)('Has', 2)('based', 2)('overall', 2)('preferred', 2)('teams', 2)('Provide', 2)('analytics', 2)('3', 2)('Technologies', 2)('modeling', 2)('8217', 2)('strategy', 2)('direction', 2)('Level', 2)('technology', 2)('changing', 2)('patterns', 2)('practices', 2)('data-hub', 2)('being', 2)('source', 2)('4', 2)('security', 2)('/', 2)('software', 2)('within', 2)('quickly', 2)(':', 2)('Healthcare', 2)('Engineering', 2)('computing', 2)('at', 2)('Description', 2)('required', 2)('requires', 2)('migrated', 1)('all', 1)('concept', 1)('integration)', 1)('DevOps', 1)('Demonstrated', 1)('Metadata', 1)('NoSQL', 1)('Business', 1)('statistics', 1)('Architects', 1)('charge', 1)('position.', 1)('stable', 1)('Parallel', 1)('downstream', 1)('balancing', 1)('govern', 1)('vast', 1)('problems.', 1)('standards', 1)("Architect'", 1)('workloads', 1)('Griffith', 1)("'Lead", 1)('direction.', 1)('virtualization', 1)('East', 1)('(optimization', 1)('Collabera', 1)('Ahead', 1)('leveraging', 1)('concepts', 1)('operating', 1)('groups', 1)('address', 1)('along', 1)('skills.', 1)('mentor', 1)('Technology', 1)('options', 1)('via', 1)('secure', 1)('teach', 1)('unstructured)', 1)('use', 1)('from', 1)('Ranger', 1)('Qualifications', 1)('governance', 1)('next', 1)('JSP', 1)('Massively', 1)('more', 1)('(structured', 1)('Summary', 1)('Javascript', 1)('real-time', 1)('cases', 1)('effort', 1)('insights', 1)('science', 1)('CyberCoders', 1)('learn', 1)('meet', 1)('proof', 1)('IBM', 1)('semi-structured', 1)('implementations', 1)('enterprise-class', 1)('SGIC', 1)('needs', 1)('requirements', 1)('confidential', 1)('NodeJS', 1)('provide', 1)('Presto', 1)('stewardship', 1)('Architectural', 1)('plus', 1)('Spark', 1)('Teradata&#', 1)('Oversee', 1)('Hive', 1)('parallel', 1)('types', 1)('All', 1)('outline', 1)('Linux', 1)('Schenectady', 1)('Kerberos', 1)('upstream', 1)('mission', 1)('including', 1)('machine', 1)('Assist', 1)('high-scale', 1)('systems', 1)('communication', 1)('defining', 1)('good', 1)('emailed', 1)('Maintain', 1)('they', 1)('ecosystems', 1)('payer', 1)('establishing', 1)('|', 1)('Previous', 1)('Responsibilities/Accountabilities:', 1)('generation', 1)('Governance', 1)('initiatives', 1)('(MySQL', 1)('research', 1)('self-starter', 1)('Technical', 1)('Job', 1)('Server)', 1)('7', 1)('receiving', 1)('Dardanelli', 1)('she', 1)('eco', 1)('dependencies', 1)('members', 1)('Security', 1)('advance', 1)('training', 1)('(HPC)', 1)('Certification', 1)('major', 1)('organize', 1)('directly', 1)('start', 1)('engagement', 1)('architecting', 1)('Success', 1)('tool', 1)('continuous', 1)('R', 1)('recommendations.', 1)('Oracle', 1)('Inc.', 1)('to:', 1)('10', 1)('LDAP', 1)('migration', 1)('Information', 1)('clearly', 1)('tools.', 1)('hub', 1)('responsible', 1)('able', 1)('ideal', 1)('potential', 1)('take', 1)('They', 1)('performance', 1)('learning).', 1)('healthcare', 1)('Dev', 1)('services', 1)('assessed', 1)('guidelines.', 1)('team-wide', 1)('Informatica', 1)('Cloud', 1)('Web', 1)('emerging', 1)('years&#', 1)('(e.g.', 1)('Utilizing', 1)('Infrastructure', 1)('Ops', 1)('distributed', 1)('written', 1)('should', 1)('analytic', 1)('enthusiasm', 1)('Strong', 1)('means', 1)('practices.', 1)('closely', 1)('relational', 1)('conjunction', 1)('processes', 1)('analytical', 1)('uncover', 1)('where', 1)('predictive', 1)('Educational', 1)('Rochester', 1)('intelligence', 1)('BS', 1)('Location', 1)('needs.', 1)('deploying', 1)('techniques', 1)('expert', 1)("projects'", 1)('PC', 1)('various', 1)('across', 1)('Advanced', 1)('C', 1)('Cloudera', 1)('jobs', 1)('implementing', 1)('mentoring', 1)('key', 1)('Directory', 1)('according', 1)('against', 1)('s', 1)('Computer', 1)('Design', 1)('orchestration', 1)('passing', 1)('Pentaho.', 1)('relevant', 1)('premise', 1)('initiative', 1)('cross-functional', 1)('ETL', 1)('warehouses', 1)('Processing', 1)('Active', 1)('environment.', 1)('understand', 1)('Demonstrate', 1)('160', 1)('Essential', 1)('developing', 1)('align', 1)('Databricks', 1)('engineers', 1)('cons', 1)('Additional', 1)('architecture)', 1)('cluster', 1)('You', 1)('management.', 1)('(ex.', 1)('Python', 1)('administration', 1)('document', 1)('Hands-on', 1)('meets', 1)('used', 1)('reporting', 1)('automation', 1)('proficiency', 1)('{emailaddress}', 1)('prescribed', 1)('kept', 1)('database', 1)('analysis', 1)('solve', 1)('organization', 1)('unified', 1)('stores', 1)('RDBMS', 1)('Perform', 1)('Position', 1)('highly-available', 1)('discipline', 1)('Be', 1)('candidate', 1)('agile', 1)('Company', 1)('capabilities', 1)('usage', 1)('Event-based/reactive', 1)('background', 1)('execution', 1)("Excellus's", 1)('SQL', 1)("SLA's", 1)('beneficial', 1)('Java', 1)('methods', 1)('verbal', 1)('successfully', 1)('EEO', 1)('Master', 1)('5', 1)('pros', 1)('critical', 1)('passion', 1)('be', 1)('run', 1)('(BPM)', 1)('platform.', 1)('requirements:', 1)('leadership', 1)('requirements.', 1)('would', 1)('industry', 1)('Kafka', 1)('ensure', 1)('opportunities.', 1)('articulate', 1)('Storm', 1)('your', 1)('technically', 1)('Flume', 1)('Collaborate', 1)('support', 1)('systems.', 1)('vendors', 1)('influencing', 1)('form', 1)('Science', 1)('Talend', 1)('related', 1)('promote', 1)('deployed', 1)('he', 1)('ecosystem', 1)('associated', 1)('contribute', 1)('Mathematics', 1)('plan', 1)('variety', 1)('high-performance-computing', 1)('field', 1)('Understand', 1)('Effective', 1)('Qualifications:', 1)('roadmaps', 1)('departments', 1)('Jobs.com', 1)('having', 1)    Lead Hadoop Data Platform Architect - Emvia Inc | Jobs.com
        Company Description
         Emvia Inc
        Job Description
          Position : &#160;Lead Hadoop Data Platform Architect
          Location : East Rochester,NY
         The 'Lead Data Architect' needs to have technically knowledge / experience to lead the effort of deploying a Hortonworks Hadoop environment and a Teradata Massively Parallel Processing environment along with the Data Management process and tool govern this environment. They would need at least 3 years&#8217; experience in this environment and at least 7 years in information management.
         Summary
         The Lead Data Architect position requires expert knowledge and technical skills in the Big Data technology and associated tools. The ideal candidate should have hands-on experience with enterprise scale applications and systems. This role requires a passion for leveraging emerging technologies and next generation architectures to solve business problems. Success in this role means having the ability to teach, mentor and take charge of a hands-on delivery team, as well as the ability to support engagement of clients on potential business opportunities.
         The position is responsible for the overall design of the data architecture, across all data types (structured, semi-structured and unstructured), balancing the need for access against security and performance requirements. This role will drive enterprise information requirements: strategy, design, access, usage and stewardship and promote Data Management &amp; Governance practices.
         Hands on experience in using MPP platforms like Teradata&#8217;s unified data platform and Healthcare payer industry experience is a major plus for this position.
         Essential Responsibilities/Accountabilities:
         &#8226; Design highly-available data hub architectures for large scale, mission critical applications and high-performance-computing (HPC) workloads
         &#8226; Provide guidance to the organization in the form of reference architectures, guidance principles, and proof of concept and reference implementations for advance analytics tools and technologies
         &#8226; Work in conjunction with Infrastructure, Dev Ops, Security and Engineering groups to drive the strategy to provide stable, secure and enterprise-class data-hub and real-time analytics systems
         &#8226; Work closely with other architects to align the projects' architectural direction with domain roadmaps, standards and reference architectures
         &#8226; Work with cross-functional departments and delivery teams to ensure that they understand the prescribed direction. Oversee the execution of key architectural initiatives within this domain
         &#8226; Hands-on in the delivery of enterprise data-hub to meet enterprise analytic and business intelligence needs. Utilizing hands-on technical skills in architecting, designing, developing and implementing large scale Big Data solutions
         &#8226; Provide guidance to other architects and engineers in the technologies being assessed and used
         &#8226; Assist Management with the training and mentoring of the team members
         &#8226; Collaborate with other teams to address upstream and downstream integration dependencies via services and SLA's
         &#8226; Demonstrate technical leadership and ability to contribute to establishing the overall solution direction
         &#8226; Be self-starter with the initiative and enthusiasm to learn new tools &amp; technologies within the Hadoop eco system
         &#8226; Maintain a working knowledge of Excellus's applications and system integration
         Minimum Qualifications:
         &#8226; BS in Computer Science, Engineering, Mathematics, or a related field required
         &#8226; 8 years of experience in architecture or relevant Technology discipline required, including 4 years software development, system architecture, and/or system administration
         &#8226; Certification from one of the Big Data vendors - Cloudera, Hortonworks, IBM, Databricks, Teradata
         &#8226; 1 year of hands-on experience with the technologies in the Hadoop ecosystem
         &#8226; 2 year of hands-on experience with MPP platforms like Teradata
         &#8226; Experience working directly with business clients to design a solution that meets business requirements; ability to clearly articulate pros and cons of various technologies and platforms and architectural options, as well as being able to document use cases, solutions and recommendations.
         &#8226; Experience data governance concepts and tools
         &#8226; Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms
         &#8226; Architecture experience in defining the outline for a team-wide development
         &#8226; Experience with Architecture patterns and practices (ex. Web architectures, cloud computing, data architecture)
         &#8226; Understand DevOps principles and work with the team to implement automation and continuous integration
         &#8226; Event-based/reactive architectures and message passing (e.g. message based patterns for orchestration and integration)
         &#8226; Technical computing (optimization, statistics and machine learning).
         &#8226; Previous experience in reporting and predictive modeling is preferred
         &#8226; Perform analysis of vast data stores and uncover insights
         &#8226; Business process modeling (BPM) experience
         &#8226; Advanced understanding of open source software development tools and solutions. Strong analytical skills with open source solutions
         &#8226; Experience with a variety of Hadoop tools such as Hive, Presto, Flume, Storm, Kafka, Spark
         &#8226; Demonstrated proficiency in one or more of Java, JSP, Javascript, Python, R, NodeJS
         &#8226; Hands on relational database experience (MySQL, Oracle, SQL Server) is beneficial
         &#8226; Hands on experience in working with Hadoop ecosystems
         &#8226; Experience using Metadata tools and practices
         &#8226; Familiarity with Master Data Management
         &#8226; Familiarity with run on premise and cloud based architecture
         &#8226; Familiarity with security tools such as Kerberos, Ranger, LDAP, Active Directory
         &#8226; Familiarity with the Linux operating system
         &#8226; Familiarity with Data virtualization
         &#8226; Familiarity with ETL tools such as Informatica, Talend and/or Pentaho.
         &#8226; Experience with agile techniques or methods
         &#8226; Educational background in Data science is preferred
         &#8226; Ability to manage multiple priorities in a quickly changing environment
         &#8226; Ability to work in a team environment
         &#8226; Ability to manage multiple priorities in a quickly changing environment
         &#8226; Ability to research, plan, organize, lead, and implement new processes or technology
         &#8226; Effective verbal and written communication and influencing skills.
         Level 1
         &#8226; Has a minimum of 8 years of experience in data warehousing and 3 years in big data architecture solutions
         &#8226; Minimum of 2 years of Healthcare experience
         Level 2
         &#8226; Has a minimum of 10 years of experience in data warehousing and 5 years in big data architecture solutions.
         &#8226; Architectural lead the migration to a big data platform where he or she successfully migrated and deployed the new the big data capabilities using MPP / Hadoop platform.
         &#8226; Minimum of 4 years of healthcare experience
        Qualifications
        Additional Information
         All your information will be kept confidential according to EEO guidelines.
             Collabera, New York City - NY
             New York - NY
             SGIC Cloud Technologies Inc, New York City - NY
             Griffith Dardanelli Architects, PC, Schenectady - NY
             C Ahead Technologies Inc., New York City - NY
             CyberCoders, New York City - NY
          Lead Hadoop Data Platform Architect
        You will start receiving jobs like this emailed to: {emailaddress}