('*', 25)('and', 24)('data', 20)('a', 17)('of', 15)('Data', 14)('to', 11)('the', 11)('with', 11)('-', 9)('on', 8)('must.', 6)('in', 6)('NJ', 6)('Hadoop', 5)('analytics', 5)('is', 5)('for', 5)('etc.', 5)('experience', 4)('plus.', 4)('The', 4)('You', 4)('Chubb', 4)('be', 4)('business', 4)('Complex', 3)('insurance', 3)('Work', 3)('programming', 3)('Parsing', 3)('engineer', 3)('solutions', 3)('are', 3)('solutions.', 3)('Engineer', 3)('will', 3)('complex', 3)('able', 3)('using', 3)('or', 3)('Experience', 3)('as', 3)('HBase', 2)('(NLP)', 2)('skills', 2)('large', 2)('design', 2)('relational', 2)('Mahout', 2)('tools', 2)('by', 2)('this', 2)('science', 2)('information', 2)('Spark', 2)('A', 2)('Hive', 2)('Brunswick', 2)('personal', 2)('Parser)', 2)('Language', 2)('R', 2)('preparation', 2)('computer', 2)('have', 2)('multiple', 2)('knowledge', 2)('should', 2)('managing', 2)('discovery', 2)('Natural', 2)('Processing', 2)('different', 2)('sets', 2)('visualization', 2)('big', 2)('background', 2)('projects', 2)('like', 2)('Pig', 2)('New', 2)('software', 2)('Knowledge', 2)('into', 2)('within', 2)('technologies', 2)('distribution', 2)('expertise', 2)('casualty', 2)('problems', 2)('(Big', 2)('forthe', 1)('focus', 1)('providescommercial', 1)('visualizing', 1)('cloud.', 1)('activities', 1)('results', 1)('decide', 1)('HDFS', 1)('prototypes', 1)('excellence', 1)('Transforms', 1)('team', 1)('financialstrength', 1)('self-starterwho', 1)('Should', 1)('Real-Time', 1)('selected', 1)('above', 1)('tasks.', 1)('wrangling', 1)('commercial', 1)('languages.', 1)('technical', 1)('analysts', 1)('highly', 1)('analyzing', 1)('from', 1)('working', 1)('0', 1)("world's", 1)('use.', 1)('Solr', 1)('diversegroup', 1)('company', 1)('Hadooop', 1)('Apache', 1)('visual', 1)('concepts', 1)('strategies', 1)('proof', 1)('(with', 1)('high', 1)('educational', 1)('requirements', 1)('cleansing', 1)('1', 1)('product', 1)('Knowledgeof', 1)('needs', 1)('applications', 1)('SkillsRequired', 1)('effective', 1)('platforms.', 1)('Python', 1)('algorithms', 1)('operations', 1)('years', 1)('including', 1)('statistical', 1)('converting', 1)('its', 1)('superior', 1)('someone', 1)('emailed', 1)('3', 1)('python', 1)('ingestion.', 1)('Bedminster', 1)('Diedre', 1)('|', 1)('analysis.', 1)('related', 1)('Significantprogramming', 1)('health', 1)('receiving', 1)('andservice', 1)('Spark.', 1)('training', 1)('certifications', 1)('turn', 1)('follows:', 1)('Vitalyst', 1)('one', 1)('Bala', 1)('another', 1)('management', 1)('MapR', 1)('2', 1)('master', 1)('that', 1)('tool', 1)('to:', 1)('jobs', 1)('target', 1)('AT&amp', 1)('distinguished', 1)('andsupplemental', 1)('Cassandra', 1)('collecting', 1)('toimplement', 1)('Parsippany', 1)('substantial', 1)('any', 1)('depending', 1)('conforming', 1)('build', 1)('With', 1)('who', 1)('architects', 1)('Ingestion', 1)('especially', 1)('Avro', 1)('databases', 1)('High-Speed', 1)('ZooKeeper', 1)('partners', 1)('JobDescription:', 1)('based', 1)('Big', 1)('neededhardware', 1)('Specificresponsibilities', 1)('exceptional', 1)('closely', 1)('localoperations', 1)('countries', 1)('she', 1)('formats.', 1)('Chukwa', 1)('Leverage', 1)('Create', 1)('profiling', 1)('Performance', 1)('needs.', 1)('techniques', 1)('outside', 1)('PA', 1)('various', 1)('implementingcomplex', 1)('Cloudera', 1)('premises', 1)('deliver', 1)('adept', 1)('job', 1)('accident', 1)('according', 1)('globally.', 1)('engineershould', 1)('Design', 1)('Piscataway', 1)('insightsusing', 1)('create', 1)('.', 1)('JSON', 1)('utilizing', 1)('XML', 1)('life', 1)('sufficient', 1)('Implement', 1)('BridgeView', 1)('understand', 1)('worked', 1)('those', 1)('handling', 1)('publicly', 1)('developing', 1)('solid', 1)('engineering', 1)('property', 1)('Pythonon', 1)('MapReduce', 1)('Ideal', 1)('Moire', 1)('technology', 1)('develop', 1)('perform', 1)('largest', 1)('development', 1)('IT', 1)('{emailaddress}', 1)('levels', 1)('ownership', 1)('stack', 1)('tune', 1)('insurer.', 1)('well', 1)('claims', 1)('model', 1)('latest', 1)('ecosystem.', 1)('being', 1)('sources', 1)('speed', 1)('candidate', 1)('capabilities', 1)('Hands', 1)('extensive', 1)('take', 1)('rules', 1)('aggregation', 1)('astrong', 1)('T', 1)('ecosystems', 1)('underwriting', 1)('offerings', 1)('54', 1)('HortonWorks', 1)('Streaming', 1)('Linux)', 1)('works', 1)('Warren', 1)('Java', 1)('tradedproperty', 1)('and/or', 1)('broad', 1)('bigdata', 1)('He', 1)('communicate', 1)('Sourcing', 1)('leadership', 1)('data-drivenanalytics', 1)('abroad', 1)('range', 1)('plus', 1)('act', 1)('Cynwyd', 1)('Cybersystems', 1)('repositories.', 1)('parsing', 1)('atsolving', 1)('loads.', 1)('your', 1)('Knowledgent', 1)('statistics', 1)('fields.', 1)('abstractions', 1)('Collection', 1)('custom', 1)('start', 1)('Excellent', 1)('form', 1)('decisions.', 1)('Interactive', 1)('clients.', 1)('datasets', 1)('high-quality', 1)('ecosystem', 1)('iseager', 1)('Tez', 1)('non-relational', 1)('sqoop', 1)('Utilize', 1)('diverse', 1)('variety', 1)('generally', 1)('other', 1)('role', 1)('Corp.', 1)('Case', 1)('"raw"', 1)('tackle', 1)('reinsurance', 1)('American', 1)('Jobs.com', 1)('requires', 1)    Data Engineer - Chubb | Jobs.com
        Data Engineer
        Chubb is the world's largest publicly tradedproperty and casualty insurer. With operations in 54 countries, Chubb providescommercial and personal property and casualty insurance, personal accident andsupplemental health insurance, reinsurance and life insurance to a diversegroup of clients. The company is distinguished by its extensive product andservice offerings, broad distribution capabilities, exceptional financialstrength, underwriting excellence, superior claims handling expertise and localoperations globally.
        JobDescription:
        The data engineer is a technical job that requires substantial expertise in abroad range of software development and programming fields. The data engineershould especially have sufficient knowledge of big data solutions to be able toimplement those on premises or in the cloud.
        A data engineer generally works on implementingcomplex big data projects with a focus on collecting, parsing, managing,analyzing and visualizing large sets of data to turn information into insightsusing multiple platforms. He or she should be able to decide on the neededhardware and software design needs and act according to the decisions. The bigdata engineer should be able to develop prototypes and proof of concepts forthe selected solutions.
        Ideal candidate for this role is someone with astrong background in computer programming, statistics, and data science who iseager to tackle problems with large, complex datasets using the latest python,R, and/or Spark. You are a self-starterwho will take ownership of your projects and deliver high-quality data-drivenanalytics solutions. You are adept atsolving diverse business problems by utilizing a variety of different tools,strategies, algorithms and programming languages.
        Specificresponsibilities are as follows:
        * Utilize the data engineering skills within and outside of the developing Chubb information ecosystem for discovery, analytics and data management
        * Work with architects, business partners and business analysts to understand requirements, design and build effective solutions.
        * You will be using Data wrangling techniques converting one "raw" form into another including data visualization, data aggregation, training a statistical model etc.
        * Create different levels of abstractions of data depending on analytics needs.
        * Hands on data preparation activities using the Hadoop technology stack
        * Implement discovery solutions for high speed data ingestion.
        * Work closely with the Data leadership team to perform complex analytics and data preparation tasks.
        * Work with various relational and non-relational data sources with the target being Hadoop based repositories.
        * Sourcing data from multiple applications, profiling, cleansing and conforming to create master data sets for analytics use.
        * Experience with Complex Data Parsing (Big Data Parser) and Natural Language Processing (NLP) Transforms on Hadoop a plus.
        * Design solutions for managing highly complex business rules within the Hadoop ecosystem.
        * Performance tune data loads.
        * Leverage visual analytics tools to communicate results of data analysis.
        SkillsRequired
        * 1-3years of solid experience in Big Data technologies a must.
        * Knowledgeof Hadooop 2.0 ecosystems, HDFS, MapReduce, Hive, Pig, sqoop, Mahout, Spark etc. a must.
        * Experience with Avro, Cassandra, Chukwa, HBase, Hive, Mahout, Pig, Spark, Tez, ZooKeeper etc. a must.
        * Significantprogramming experience (with above technologies as well as Java, R and Pythonon Linux) a must.
        * Knowledge of any commercial distribution like HortonWorks, Cloudera, MapR etc. a must.
        * Excellent working knowledge of relational databases, HBase etc.
        * A computer science or related educational background
        * Data visualization tool experience a plus.
        * Hadoop certifications a plus.
        * Experience with Complex Data Parsing (Big Data Parser) a must. Should have worked on XML, JSON and other custom Complex Data Parsing formats.
        * Natural Language Processing (NLP) skills with experience in Apache Solr, Python a plus
        * Knowledge of High-Speed Data Ingestion, Real-Time Data Collection and Streaming is a plus.
             Vitalyst, Bala Cynwyd - PA
             Case Interactive, Piscataway - NJ
             AT&amp;T, Bedminster - NJ
             BridgeView IT, Parsippany - NJ
             Diedre Moire Corp., New Brunswick - NJ
             American Cybersystems, New Brunswick - NJ
             Knowledgent, Warren - NJ
          Data Engineer
        You will start receiving jobs like this emailed to: {emailaddress}