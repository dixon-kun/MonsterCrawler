('*', 31)('and', 17)('of', 13)('to', 9)('-', 9)('Solutions', 8)('Knowledge', 7)('IL', 7)('with', 6)('systems', 5)('data', 5)('We', 4)('our', 4)('ETL', 4)('Chicago', 4)('concepts', 4)('the', 4)('Hadoop', 3)('distributed', 3)('do', 3)('design', 3)('are', 3)('configuration', 3)('for', 3)('/', 3)('Cloudera', 3)('management', 3)('as', 3)('in', 3)('Consultant', 3)('patterns', 3)('background', 2)('(e.g.', 2)('knowledge', 2)('Business', 2)('complex', 2)('Wolters', 2)('libraries', 2)('Have:', 2)('Consultants', 2)('common', 2)('people', 2)('up', 2)('and/or', 2)('behind', 2)('jobs', 2)('business', 2)('networking', 2)('warehousing', 2)('on', 2)('experience', 2)('Chef)', 2)('or', 2)('consulting', 2)('Meadows', 2)('packages', 2)('create', 2)('Konica', 2)('pipelines', 2)('Experience', 2)('Minolta', 2)('work', 2)('Puppet', 2)('Kluwer', 2)('Familiarity', 2)('seeking', 2)('Understanding', 2)('Rolling', 2)('mass', 2)('L', 2)('running', 2)('client', 2)('operations', 1)('Queuing', 1)('comfort', 1)('remarkable', 1)('administration', 1)('Hire', 1)('leads', 1)('MySQL', 1)('contributions', 1)('availability', 1)('Demonstrated', 1)('day.', 1)('3', 1)('environment', 1)('team.', 1)('Services', 1)('clusters', 1)('smart', 1)('continuity', 1)('customers', 1)('his', 1)('emailed', 1)('exceptional', 1)('Solid', 1)('NATIONAL', 1)('Batch', 1)('synchronization', 1)('every', 1)('they', 1)('not', 1)('strive', 1)('to:', 1)('term', 1)('basics', 1)('like', 1)('individuals', 1)('each', 1)('debug', 1)('Bonus:', 1)('where', 1)('|', 1)('enjoy', 1)('methods', 1)('group.', 1)('System', 1)('consultants', 1)('intensity', 1)('individual', 1)('casual', 1)('techniques', 1)('network', 1)('currently', 1)('familiarity', 1)('looking', 1)('everything', 1)('mission.', 1)('receiving', 1)('Must', 1)('classification', 1)('PySpark)', 1)('team', 1)('understanding', 1)('key', 1)('Team', 1)('strong', 1)('vs.', 1)('pipeline', 1)('things.', 1)('working', 1)('getting', 1)('{emailaddress}', 1)('Optimization', 1)('act', 1)('this', 1)('Group', 1)('members', 1)('Working', 1)('feel', 1)('English', 1)('TechnoSphere', 1)('(including', 1)('troubleshooting', 1)('VLANs', 1)('clustering', 1)('use', 1)('from', 1)('IPC/RPC', 1)('her', 1)('system', 1)('start', 1)('2', 1)('basic', 1)('Data', 1)('function', 1)('OS', 1)('fundamentals', 1)('Science', 1)('memory', 1)('Fallacies', 1)('Fluent', 1)('Oracle', 1)('Professional', 1)('Should', 1)('Inc.', 1)('customer', 1)('Consulting', 1)('valued', 1)('join', 1)('engineering', 1)('will', 1)("company's", 1)('gathering', 1)('computing', 1)('experience.', 1)('is', 1)('locations', 1)('Virtual', 1)('an', 1)('hardware', 1)('at', 1)('want', 1)('You', 1)('regression', 1)('requirements', 1)('goal', 1)('make', 1)('how', 1)('setting', 1)('Spark', 1)('many', 1)('At', 1)('product', 1)('File', 1)('who', 1)('following:', 1)('Common', 1)('coming', 1)('device', 1)('Messaging', 1)('engagements', 1)('architecture', 1)('short', 1)('PostgreSQL', 1)('High', 1)('solve', 1)('cases.', 1)('Concurrency', 1)('Jobs.com', 1)('UnitedHealth', 1)('typical', 1)    Solutions Consultant - Cloudera | Jobs.com
        We are currently seeking Solutions Consultants to join our team.
        Solutions Consultants work on the consulting team as members of our Professional Services group. Cloudera Solutions Consultant do not act as typical consultants - they function as Hadoop Team leads at our client locations for short term engagements and do everything from getting the product up and running to engineering data to solve key use cases. We are seeking exceptional individuals with strong client consulting experience.
        At Cloudera, our goal is to make each individual feel valued for his or her contributions to the company's mission. We are looking for smart people who want to do remarkable things. We strive to create an environment of casual intensity where people enjoy coming to work every day.
        Must Have:
        * Working knowledge of setting up and running Hadoop clusters
        * Knowledge on how to create and debug Hadoop jobs
        * Consulting background and/or comfort in working with customers
        * Experience in Spark (including PySpark), and basic familiarity with regression, classification, and clustering techniques
        * Data Science background and/or experience
        * Demonstrated experience gathering and understanding customer business requirements
        * Familiarity with data warehousing concepts
        * Knowledge of distributed systems
        * Knowledge of complex data pipelines and ETL
        * Knowledge of common ETL packages / libraries
        * Understanding of configuration management systems (e.g. Puppet, Chef) and concepts behind mass configuration
        * Fluent in English
        Should Have:
        * Familiarity with data warehousing concepts
        * Knowledge of distributed systems
        * Knowledge of complex data pipelines and ETL
        * Knowledge of common ETL packages / libraries
        Bonus:
        * Understanding of configuration management systems (e.g. Puppet, Chef) and concepts behind mass
        Experience with many of the following:
        * Oracle, MySQL or PostgreSQL
        * Concurrency and synchronization
        * Fallacies of distributed computing
        * Common IPC/RPC methods and patterns
        * High availability and business continuity
        * Queuing patterns and pipeline design
        * Batch operations
        * Messaging systems and patterns
        * Solid OS / networking fundamentals
        * Virtual memory management
        * File system design
        * Optimization and troubleshooting
        * System administration knowledge
        * L2 vs. L3 networking, network architecture, VLANs, hardware device design basics
             Wolters Kluwer, Chicago - IL
             Konica Minolta Business Solutions, Rolling Meadows - IL
             TechnoSphere, Inc., Chicago - IL
             Wolters Kluwer, Chicago - IL
             Konica Minolta Business Solutions, Rolling Meadows - IL
             UnitedHealth Group, Chicago - IL
             Hire Solutions, NATIONAL - IL
          Solutions Consultant
        You will start receiving jobs like this emailed to: {emailaddress}