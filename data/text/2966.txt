('and', 12)('-', 10)('with', 9)('VA', 9)('of', 8)('data', 6)('to', 5)('Experience', 5)('as', 5)('such', 5)('Big', 4)('JOB', 4)('analytic', 4)('Data', 4)('platform', 3)('or', 3)('ingestion', 3)('utilizing', 3)('pipelines', 3)('that', 3)('will', 3)('frameworks', 3)('Engineer', 3)('Herndon', 3)('experience', 3)('a', 3)('all', 2)('sources', 2)('solutions', 2)('distributed', 2)('systems', 2)('OVERVIEW', 2)('Hadoop', 2)('using', 2)('Alexandria', 2)('EXPERIENCE', 2)('source', 2)('our', 2)('tools', 2)('various', 2)('be', 2)('base', 2)('implement', 2)('open', 2)('from', 2)('this', 2)('Our', 2)('cluster', 2)('data.', 2)('big', 2)('REQUIRED', 1)('NoSQL', 1)('Agile', 1)('Proficient', 1)('focus', 1)('RabbitMQ', 1)('leads', 1)('Rosslyn', 1)('through', 1)('managers', 1)('issues', 1)('Inc.', 1)('adding', 1)('We', 1)('derive', 1)('based', 1)('knowledge', 1)('Extend', 1)('Advanced', 1)('Company', 1)('capabilities', 1)('edge', 1)('(ARTI)', 1)('Logstash', 1)('Building', 1)('emailed', 1)('evaluate', 1)('Staffing', 1)('unstructured', 1)('cutting', 1)('Products', 1)('new', 1)('Kearney', 1)('HDFS', 1)('querying', 1)('like', 1)('solution', 1)('Pig', 1)('capability', 1)('Identify', 1)('|', 1)('Management', 1)('Java', 1)('(Perl', 1)('crunch', 1)('Create', 1)('principles', 1)('Legal', 1)('maintain', 1)('professional', 1)('are', 1)('JavaScript)', 1)('best', 1)('techniques', 1)('project', 1)('Good', 1)('Ability', 1)('for', 1)('Scrum', 1)('integration', 1)('looking', 1)('provides', 1)('scientists', 1)('shared', 1)('Technologies', 1)('receiving', 1)('across', 1)('multitude', 1)('jobs', 1)('degree', 1)('This', 1)('equivalent', 1)("Bachelor's", 1)('understanding', 1)('implementing', 1)('operating', 1)('by', 1)('on', 1)('language', 1)('technical', 1)('Resource', 1)('MapReduce', 1)('ingest', 1)('Kafka', 1)('CLIENT', 1)('massive', 1)('messaging', 1)('Cassandra', 1)('petabytes', 1)('requested', 1)('Palmer', 1)('Group', 1)('Knowledge', 1)('Martin', 1)('primary', 1)('services', 1)('computing', 1)('Storm', 1)('Hunter', 1)('ETL', 1)('Flume', 1)('working', 1)('Impala', 1)('structured', 1)('RESPONSIBILITIES', 1)('start', 1)('2', 1)('Lockheed', 1)('building', 1)('Cloudera/Hortonworks', 1)('configure', 1)('&amp', 1)('environment.', 1)('technologies', 1)('Scripting', 1)('insights', 1)('to:', 1)('clients.', 1)('MongoDB', 1)('Allied', 1)('Engineering', 1)('ongoing', 1)('can', 1)('v', 1)('GEICO', 1)('is', 1)('in', 1)('You', 1)('distributions', 1)('any', 1)('Springfield', 1)('technologies.', 1)('develop', 1)('amounts', 1)('utilize', 1)('Proficiency', 1)('client', 1)('functionality', 1)('build', 1)('optimal', 1)('Spark', 1)('document', 1)('development', 1)('multiple', 1)('Hive', 1)('DESIRED', 1)('{emailaddress}', 1)('Elasticsearch', 1)('Manassas', 1)('Jobs.com', 1)('included', 1)('The', 1)('Python', 1)('Woodbridge', 1)('required', 1)('stream-processing', 1)('actionable', 1)('provide', 1)('practices', 1)('solve', 1)('databases', 1)('Turas', 1)('position', 1)('the', 1)('requires', 1)('enrichment', 1)    Big Data Engineer - Herndon, VA - Turas Group | Jobs.com
          CLIENT OVERVIEW
         Our client is utilizing cutting edge open source technologies and frameworks to derive actionable insights from massive amounts of data. Our solution provides capability to ingest petabytes of structured and unstructured data and build analytic pipelines that crunch through this data.
          JOB OVERVIEW
         We are looking for a Big Data Engineer that will utilize our base platform to develop ingestion and analytic pipelines utilizing a multitude of open source technologies. The primary focus will be on implementing optimal solutions utilizing best practices that can be shared across all our clients. This position requires working with technical leads, data scientists and project managers in a Scrum based Agile environment.
          JOB RESPONSIBILITIES
          Create, configure, implement, document and maintain ingestion, enrichment and analytic pipelines using distributed big data platform
          Extend base platform functionality by adding new ingestion and analytic sources
          Identify, evaluate and implement big data tools and frameworks required to provide requested capabilities
          JOB EXPERIENCE REQUIRED
          Java development experience
          Scripting language experience (Perl, Python, JavaScript)
          Proficient understanding of distributed computing principles
          Proficiency with Hadoop v2, MapReduce, HDFS
          Experience with building stream-processing systems, using solutions such as Storm or Spark
          Experience with integration of data from multiple data sources
          Experience with NoSQL databases, such as Elasticsearch, MongoDB, Cassandra
          Knowledge of various ETL techniques and frameworks, such as Flume, Logstash
          Experience with various messaging systems, such as Kafka or RabbitMQ
          Experience with Cloudera/Hortonworks distributions
          Bachelor's degree or equivalent professional experience
          JOB EXPERIENCE DESIRED
          Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
          Management of Hadoop cluster, with all included services
          Ability to solve any ongoing issues with operating the cluster
             Lockheed Martin, Herndon - VA
             Palmer Legal Staffing, Alexandria - VA
             Kearney &amp; Company, Alexandria - VA
             Hunter Engineering, Woodbridge - VA
             Allied Building Products, Manassas - VA
             Advanced Resource Technologies, Inc. (ARTI), Rosslyn - VA
             GEICO, Springfield - VA
          Big Data Engineer - Herndon, VA
        You will start receiving jobs like this emailed to: {emailaddress}