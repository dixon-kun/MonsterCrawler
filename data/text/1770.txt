('and', 53)('data', 24)('the', 24)('to', 23)('160', 17)('of', 16)('with', 15)('Data', 13)('8217', 12)('solutions', 11)('in', 11)('or', 11)('Big', 9)('Kylo', 8)('s', 8)('for', 8)('&#', 7)('tools', 7)('Architect', 7)('-', 7)('will', 7)('on', 7)('Experience', 7)('experience', 6)('Think', 6)('requirements', 6)('Principal', 6)('including', 6)('security', 6)('Apache', 5)('design', 5)('a', 5)(':&#', 5)('such', 5)('as', 5)('and/or', 5)('designing', 4)('technical', 4)('management', 4)('have', 4)('Hadoop', 4)('You', 4)('architectures', 4)('source', 4)('Americas-United', 4)('using', 4)('integration', 4)('be', 4)('an', 4)('Lead', 3)('understanding', 3)('from', 3)('customer', 3)('how', 3)('Spark', 3)('systems', 3)('framework', 3)('our', 3)('open', 3)('customer&#', 3)('They', 3)('performance', 3)('The', 3)('enterprise', 3)('etc.)', 3)('teams', 3)('implementing', 3)('both', 3)('8211', 3)('complex', 3)('lake', 3)('big', 3)('helping', 3)('all', 2)('Requirements:', 2)('environment', 2)('AVON', 2)('what', 2)('metadata', 2)('use', 2)('recommend', 2)('work', 2)('Integration', 2)('Hive', 2)('help', 2)('years', 2)('good', 2)('Solid', 2)('Junction', 2)('network', 2)('re', 2)('Work', 2)('quality', 2)('leading', 2)('architecting', 2)('Development', 2)('storage', 2)('framework.&#', 2)('based', 2)('distributed', 2)('Strong', 2)('overall', 2)('testing', 2)('are', 2)('jobs', 2)('best', 2)('Ability', 2)('Cloudera', 2)('offerings', 2)('ETL', 2)('Degree', 2)('understand', 2)('is', 2)('it', 2)('views', 2)('flows', 2)('levels', 2)('center', 2)('analysis', 2)('responsible', 2)('BI', 2)('thinking', 2)('customers', 2)('around', 2)('developers', 2)('Java', 2)('business', 2)('working', 2)('software', 2)('Teradata', 2)('Science', 2)('ecosystem', 2)('sales', 2)('you', 2)('AZ', 2)('building', 2)('lead', 2)('resources', 1)('170529', 1)('Responsibilities:', 1)('States-North', 1)('NoSQL', 1)('Preferred', 1)('post-', 1)('project.&#', 1)('Present', 1)('returning', 1)('difference', 1)('HDFS', 1)('presented', 1)('Global', 1)('large', 1)('team', 1)('REST/JSON', 1)('XML/SOAP', 1)('+', 1)('transformed.&#', 1)('Carolina-Charlotte', 1)('supporting', 1)('concepts', 1)('(log', 1)('interpret', 1)('You&#', 1)('warehousing', 1)('Corp.', 1)('implement', 1)('Technology', 1)('industry!', 1)('outcomes', 1)('Cardinal', 1)('CTO', 1)('network-based', 1)('consumption', 1)('Ranger', 1)("world's", 1)('certified', 1)('type', 1)('today', 1)('more', 1)('started', 1)('pipeline', 1)('Americas', 1)('States-New', 1)('must', 1)('hardware', 1)('join', 1)('this', 1)('presentation', 1)('setup', 1)('can', 1)('learn', 1)('following', 1)('strategies', 1)('scripting', 1)('IBM', 1)('process', 1)('monitoring', 1)('Familiarity', 1)('minimum', 1)('preferably', 1)('Teradata&#', 1)('end', 1)('Kerberos', 1)('responsibilities', 1)('Significant', 1)('extensions', 1)('A', 1)('product', 1)('may', 1)('States-Illinois-Chicago', 1)('Specific', 1)('applications', 1)('produce', 1)('tier', 1)('third', 1)('documentation', 1)('perform', 1)('Linux', 1)('Apply', 1)('ignite', 1)("Master's", 1)('Java/.NET', 1)('hiring', 1)('through', 1)('developer', 1)('bottleneck', 1)('writing', 1)('Director', 1)('Bachelor&#', 1)('production', 1)('(customer', 1)('MuleSoft', 1)('them', 1)('Installation', 1)('Plano', 1)('AT&amp', 1)('lineage', 1)('system.', 1)('|', 1)('End', 1)('doing', 1)('related', 1)('Perl', 1)('meta', 1)('out', 1)('Architect-', 1)('looking', 1)('Key', 1)('receiving', 1)('challenges.&#', 1)('Join', 1)('commits', 1)('GreenPlum/HAWQ', 1)('approaches', 1)('bash', 1)('onsite', 1)('training', 1)('logging', 1)('IL', 1)('you&#', 1)('one', 1)('directly', 1)('Netezza&#', 1)('engineer', 1)('APIs', 1)('system', 1)('remotely', 1)('their', 1)('2', 1)('classroom', 1)('shell', 1)('Database', 1)('part', 1)('consult', 1)('Oracle', 1)('than', 1)('to:', 1)('15', 1)('effective', 1)('MongoDB', 1)('solutions.', 1)('Analytics', 1)('Unix', 1)('LDAP', 1)('Cassandra', 1)('debugging', 1)('Hortonworks', 1)('experience)', 1)('Custom', 1)('raw', 1)('(jconsole)', 1)('experience:', 1)('Do', 1)('(Kafka', 1)('deploying', 1)('experienced', 1)('PS', 1)('Solution', 1)('architects', 1)('most', 1)('plan', 1)('scripts', 1)('engagements', 1)('consumed', 1)('drive', 1)('presentation.&#', 1)('NiFi', 1)('WA', 1)('Enterprise', 1)('Recommend', 1)('Document', 1)('availability', 1)('current', 1)('We', 1)('Infrastructure', 1)('knowledge', 1)('Tulsa', 1)('Network)', 1)('implementation', 1)('written', 1)('deployments', 1)('York', 1)('Services', 1)('Applied', 1)('Opportunity/Affirmative', 1)('get', 1)('Keep', 1)('Products', 1)('Mentor', 1)('closely', 1)('Intellectual', 1)('optimally', 1)('eco-system', 1)('queries', 1)('pre-and', 1)('vision', 1)('structure&#', 1)('Storage', 1)('roadmap', 1)('profiling', 1)('project', 1)('(Kerberos/SPNEGO).', 1)('Tool', 1)('3', 1)('various', 1)('between', 1)('Exadata&#', 1)('Full-time', 1)('terms', 1)('facing)', 1)('modeling', 1)('packages', 1)('Linear', 1)('MapReduce', 1)('against', 1)('Computer', 1)('Design', 1)('Thinker?&#', 1)('large-scale', 1)('Travel', 1)('/or', 1)('tuning', 1)('.', 1)('interest', 1)('needed.', 1)('enterprises', 1)('Action', 1)('Professional', 1)('present', 1)('prove/show', 1)('developing', 1)('engineers', 1)('optimize', 1)('Primary', 1)('Write', 1)('elicit', 1)('Ambari', 1)('develop', 1)('Python', 1)('administration', 1)('any', 1)('party', 1)('veterans.', 1)('templates', 1)('third-party', 1)('{emailaddress}', 1)('Solr', 1)('(Hardware', 1)('Spring', 1)('Manager', 1)('practices', 1)('solve', 1)('York-New', 1)('T', 1)('proposed', 1)('Deliver', 1)('JMX)', 1)('States-Georgia-Atlanta', 1)('world', 1)('Analyze', 1)('previous', 1)('discipline', 1)('processes.', 1)('Company', 1)('PIG', 1)('4', 1)('transformation', 1)('(Tibco', 1)('emailed', 1)('five', 1)('know', 1)('background', 1)('highly', 1)('OK', 1)('like', 1)('success', 1)('server', 1)('communications', 1)('(or', 1)('SQL', 1)('become', 1)('passionate', 1)('often', 1)('verbal', 1)('people', 1)('some', 1)('Employer', 1)('understood', 1)('ROI', 1)('scale', 1)('Streaming', 1)('OSS', 1)('Big&#', 1)('leader', 1)('selecting', 1)('equivalent', 1)('processing', 1)('Equal', 1)('Property', 1)('by', 1)('takes', 1)('about', 1)('Camas', 1)('customers&#', 1)('ensure', 1)('(HBase', 1)('consulting', 1)('own', 1)('Knowledge', 1)('system-wide', 1)('into', 1)('Storm', 1)('strategy', 1)('your', 1)('custom', 1)('start', 1)('world&#', 1)('way', 1)('Excellent', 1)('translate', 1)('properly', 1)('Evanston', 1)('75%', 1)('Services/Consulting', 1)('technologies', 1)('junior', 1)('j', 1)('up', 1)('Engineering', 1)('etc.', 1)('include:', 1)('devise', 1)('CIO', 1)('globally', 1)('at', 1)('TX', 1)('when', 1)('setting', 1)('More', 1)('TB', 1)('users', 1)('EDW', 1)('Science.', 1)('Sentry', 1)('Hardware', 1)('ingestion', 1)('Participate', 1)('Jobs.com', 1)    Think Big Principal Data Architect - Teradata | Jobs.com
          Think Big Principal Data Architect-170529
          Join Think Big Analytics, the world's leader in designing and building highly effective Big Data solutions. We are looking for an experienced engineer to become part of the Americas team, working with leading enterprises to design and implement solutions using our Kylo open source data lake framework.&#160;&#160;&#160;&#160; The Principal Data Architect will consult with customers both onsite and remotely and will be responsible for designing and developing data lake solutions, helping to solve some of the world&#8217;s most complex big data challenges.&#160; They will be the Lead Data Architect, and will own how data flows through one or more of our solutions, both in and out, raw and transformed.&#160;&#160; They have to elicit and lead thinking on requirements such as quality, lineage, security and meta data, drive overall data strategy and design, and implementation of supporting tools and processes. The Principal Data Architect will lead thinking on how data is presented and consumed by users, from views to BI presentation.&#160; They must have a good understanding of best practices to optimally structure&#160; for consumption from an open source big data system.
          Key Responsibilities:
          The Principal Data Architect will be responsible for helping customers get started using our Kylo open source framework.&#160; Specific responsibilities may include:
            Primary and Lead Data and Solution Architect on a project.&#160; End to end data pipeline knowledge including metadata, security, data quality, data modeling, building custom views for applications and BI Tool presentation when needed.
            Present the Kylo roadmap, vision, proposed data lake architectures and business outcomes to all levels &#8211; developers, architects, CTO, CIO
            Work directly with customer&#8217;s technical resources to devise and recommend solutions based on the understood requirements
            Document and present complex architectures for the customer&#8217;s technical teams
            Recommend and design integration with third-party systems and network management tools
            Design and recommend approaches for big data ingestion strategies from any data source or type, including use of leading third party tools and their integration with overall metadata management
            Deliver architectures for Big Data including systems security and data management
            Analyze complex distributed production deployments, and develop a plan to optimize performance
            Hardware and system software design, setup and testing
            Installation and testing of Kylo framework
            Development of data flows and templates, often working with the customer&#8217;s developers to help them learn how to use Kylo
            Development of Java extensions to the Kylo framework
            Custom integration of the Kylo framework to customer systems
            Write and produce technical documentation
            Lead Kylo developer training in a classroom setting
            Mentor junior engineers
            Work closely with Think Big&#8217; teams at all levels to help ensure the success of project consulting engagements with customer
            Participate in the pre-and post- sales process, helping both the sales and product teams to interpret customers&#8217; requirements
            Keep current with the Hadoop Big Data ecosystem technologies
            Travel up to 75%
          Requirements:
            You&#8217;re passionate about what you&#8217;re doing and ignite people around you
            You know your way around OSS and can prove/show it
            You are on good terms with Infrastructure (Hardware, Storage, Network), Java/.NET, and SQL . You have an interest in Data Science and understand the difference between Data Engineering and Applied Science.
            Master's Degree or Bachelor&#8217;s Degree in Computer Science or related discipline (or equivalent work experience) and the following minimum experience:
            More than five years of Professional Services (customer facing) experience architecting large scale storage, data center and /or globally distributed solutions
            2+ years designing and deploying 3 tier architectures or large-scale Hadoop solutions
            Ability to understand and translate customer business requirements into technical requirements
            Excellent verbal and written communications
            Experience with ETL solutions on Hadoop
            Experience implementing data transformation and processing solutions using Apache PIG, Hive or Spark
            Experience designing data queries against data in the HDFS environment using tools such as Apache Hive
            Experience implementing MapReduce and/or Spark jobs
            Experience with Ambari and/or Cloudera Enterprise Manager and Director
            Strong experience implementing software and/or solutions in the enterprise Linux or Unix environment
            Strong understanding with various enterprise security solutions such as LDAP and/or Kerberos, and Hadoop security packages such as Ranger or Sentry
            Familiarity with scripting tools such as bash shell scripts, Python and/or Perl
            Significant previous work writing to network-based APIs, preferably REST/JSON or XML/SOAP
            Solid background in Database administration or design
            Experience in architecting data center solutions &#8211; properly selecting server and storage hardware based on performance, availability and ROI requirements
            Ability to perform system-wide bottleneck analysis including network analysis and performance tuning
          Preferred Requirements:
            Experience with Apache NiFi
            Knowledge of the data management eco-system including concepts of data warehousing, ETL, data integration, etc.
            Solid understanding of the Java ecosystem and enterprise offerings, including debugging and profiling tools (jconsole), logging and monitoring tools (log4j, JMX), and security offerings (Kerberos/SPNEGO).
            Streaming experience (Kafka, Storm, Spark, Solr, etc.)
            NoSQL experience (HBase, Cassandra, MongoDB, etc.)
            EDW experience &#8211; the Teradata&#8217;s, Netezza&#8217;s, GreenPlum/HAWQ, Exadata&#8217;s of the world
            Integration Products experience (Tibco, MuleSoft, IBM, Oracle, Spring Integration, etc.)
            Hortonworks or Cloudera certified
          Do you have what it takes to be a Big Thinker?&#160; Apply today to join the best in the industry!
           Think Big, A Teradata Company is an Equal Opportunity/Affirmative Action Employer and commits to hiring returning veterans.
           TB15
          :&#160;Services/Consulting
          :&#160;Full-time
          :&#160;Americas-United States-Illinois-Chicago
          :&#160;Americas-United States-Georgia-Atlanta, Americas-United States-New York-New York, Americas-United States-North Carolina-Charlotte
          :&#160;Global PS
             AT&amp;T, Plano - TX
             Linear Technology Corp., Camas - WA
             Tulsa - OK
             Cardinal Intellectual Property, Evanston - IL
             AVON, Apache Junction - AZ
             AVON, Apache Junction - AZ
          Think Big Principal Data Architect
        You will start receiving jobs like this emailed to: {emailaddress}